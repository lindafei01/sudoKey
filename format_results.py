
import json
import os

# --- Configuration ---
# The input file generated by the inference script.
INPUT_JSONL_FILE = "inference_results/v2-llama3-medical-dpo-lora-attn-mlp-20epochs-1e-5_inference_results.jsonl"

# The name for the human-readable markdown output file.
OUTPUT_MD_FILE = f"inference_results/{INPUT_JSONL_FILE.split('/')[-1].split('.')[0]}_readable_results.md"
# --- End of Configuration ---

def format_chat_history(chat_history):
    """Formats a list of chat messages into a readable string."""
    formatted_string = ""
    for message in chat_history:
        role = message.get("role", "unknown").capitalize()
        content = message.get("content", "")
        # First, replace newlines in the content itself for blockquote formatting
        formatted_content = content.replace('\n', '\n> ')
        # Then, build the final string
        formatted_string += f"**{role}:**\n> {formatted_content}\n\n"
    return formatted_string.strip()

def main():
    """
    Reads a JSONL file with inference results and converts it into a
    human-readable markdown file.
    """
    print(f"ðŸš€ Starting to format results from '{INPUT_JSONL_FILE}'...")

    if not os.path.exists(INPUT_JSONL_FILE):
        print(f"ðŸš¨ Error: Input file not found at '{INPUT_JSONL_FILE}'")
        print("Please run the inference script first to generate the results file.")
        return

    # Ensure the output directory exists
    output_dir = os.path.dirname(OUTPUT_MD_FILE)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)

    results = []
    with open(INPUT_JSONL_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                results.append(json.loads(line))
            except json.JSONDecodeError:
                print(f"Warning: Could not decode a line in the input file: {line.strip()}")
                continue
    
    # Sort results by index to ensure order, just in case.
    results.sort(key=lambda x: x.get('index', 0))

    with open(OUTPUT_MD_FILE, 'w', encoding='utf-8') as outfile:
        outfile.write(f"# Inference Results for `{os.path.basename(INPUT_JSONL_FILE)}`\n\n")
        
        for result in results:
            if "error" in result:
                outfile.write(f"## Sample {result.get('index', 'N/A')} (Error)\n\n")
                outfile.write(f"An error occurred during processing: `{result['error']}`\n\n")
                outfile.write("---\n\n")
                continue

            index = result.get("index", "N/A")
            prompt_chat = result.get("prompt_chat", [])
            ground_truth = result.get("ground_truth", "")
            model_response = result.get("model_generated_response", "")

            outfile.write(f"## Sample {index}\n\n")

            outfile.write("### ðŸ’¬ Prompt\n\n")
            outfile.write(f"{format_chat_history(prompt_chat)}\n\n")
            
            outfile.write("### âœ… Ground Truth Response\n\n")
            # FIX: Perform the string replacement outside the f-string expression
            formatted_gt = ground_truth.replace('\n', '\n> ')
            outfile.write(f"> {formatted_gt}\n\n")

            outfile.write("### ðŸ¤– Model's Generated Response\n\n")
            # FIX: Perform the string replacement outside the f-string expression
            formatted_model_response = model_response.replace('\n', '\n> ')
            outfile.write(f"> {formatted_model_response}\n\n")

            outfile.write("---\n\n")

    print(f"ðŸŽ‰ Successfully formatted {len(results)} samples.")
    print(f"ðŸ“„ Human-readable results saved to: {OUTPUT_MD_FILE}")


if __name__ == "__main__":
    main()
